import os
import json
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import requests

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
TOGETHER_API_KEY = "tgp_v1_bkDzfW5uXkhF5L5SgvcDPaAF5lN2DdzGEPYq1_y0Hk0"
LLM_MODEL = "meta-llama/Llama-3-70b-chat-hf"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
VECTOR_STORE_PATH = "vector_store.json"  # ÙØ§ÛŒÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ú©Ù‡ Ø§Ø² Ù‚Ø¨Ù„ Ø¨Ø§ÛŒØ¯ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
SIMILARITY_THRESHOLD = 0.7  # Ø¢Ø³ØªØ§Ù†Ù‡ Ø´Ø¨Ø§Ù‡Øª Ú©Ù…ÛŒ Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª ØªØ§ Ù…ÙˆØ§Ø±Ø¯ Ø¨ÛŒØ´ØªØ±ÛŒ Ø´Ø§Ù†Ø³ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ (ÛŒÚ© Ø¨Ø§Ø± Ø¯Ø± Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡) ---
print("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯...")
embedder = SentenceTransformer(EMBEDDING_MODEL)
print("Ù…Ø¯Ù„ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ ---
try:
    with open(VECTOR_STORE_PATH, "r", encoding="utf-8") as f:
        knowledge_base = json.load(f)
    print(f"Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ø§Ø² '{VECTOR_STORE_PATH}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. ({len(knowledge_base)} Ø¢ÛŒØªÙ…)")
except FileNotFoundError:
    print(f"Ø®Ø·Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ: ÙØ§ÛŒÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ '{VECTOR_STORE_PATH}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    exit()
except json.JSONDecodeError:
    print(f"Ø®Ø·Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ: ÙØ§ÛŒÙ„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ '{VECTOR_STORE_PATH}' ÙØ±Ù…Øª JSON Ù…Ø¹ØªØ¨Ø±ÛŒ Ù†Ø¯Ø§Ø±Ø¯.")
    exit()


# --- ØªÙˆØ§Ø¨Ø¹ API Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÛŒØ§Ù… Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ ---

def generate_tags(user_query, support_tags):
    """ØªÚ¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ù¾ÛŒØ§Ù… Ø¨Ù‡ÛŒÙ†Ù‡ (system/user) ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}"}

    payload = {
        "model": LLM_MODEL,
        "messages": [
            {
                "role": "system",
                "content": f"""Ø´Ù…Ø§ ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªÙ† Ù‡Ø³ØªÛŒØ¯. ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ Ø§Ù†ØªØ®Ø§Ø¨ ØªÚ¯â€Œ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø± Ø§Ø² Ù…ÛŒØ§Ù† Ù„ÛŒØ³Øª Ø²ÛŒØ± Ø§Ø³Øª. ÙÙ‚Ø· Ø®Ø±ÙˆØ¬ÛŒ JSON Ø¢Ø±Ø§ÛŒÙ‡â€ŒØ§ÛŒ Ø¨Ø¯Ù‡ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÙ‡.
ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø²: {json.dumps(support_tags, ensure_ascii=False)}"""
            },
            {
                "role": "user",
                "content": f"Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±: \"{user_query}\""
            }
        ],
        "temperature": 0.0,
        "max_tokens": 100,
        "response_format": {"type": "json_object"}  # Ù…Ø¯Ù„ Ø±Ø§ Ù…Ø¬Ø¨ÙˆØ± Ø¨Ù‡ ØªÙˆÙ„ÛŒØ¯ JSON Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    }

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        tags = json.loads(response.json()["choices"][0]["message"]["content"])
        return tags if isinstance(tags, list) else []
    except Exception as e:
        print(f"[Ø®Ø·Ø§ÛŒ ØªÚ¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ]: {e}")
        return []


def generate_response(user_query, context_docs):
    """Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ù¾ÛŒØ§Ù… Ø¨Ù‡ÛŒÙ†Ù‡ (system/user) ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not context_docs:
        return "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù¾Ø§Ø³Ø® Ù…Ø´Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ù…Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ø¨Ù¾Ø±Ø³ÛŒØ¯."

    context_text = "\n\n---\n\n".join(
        [f"Ù…ÙˆØ±Ø¯ ÛŒØ§ÙØª Ø´Ø¯Ù‡ {i + 1}:\nØ³ÙˆØ§Ù„: {item['question']}\nÙ¾Ø§Ø³Ø®: {item['answer']}" for i, item in
         enumerate(context_docs)]
    )

    url = "https://api.together.xyz/v1/chat/completions"
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}"}

    payload = {
        "model": LLM_MODEL,
        "messages": [
            {
                "role": "system",
                "content": """Ø´Ù…Ø§ ÛŒÚ© Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø®ÙˆØ´â€ŒØ¨Ø±Ø®ÙˆØ±Ø¯ Ù‡Ø³ØªÛŒØ¯. ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø± ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø±ØªØ§Ù† Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
- Ù¾Ø§Ø³Ø® Ø¨Ø§ÛŒØ¯ Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡ØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø®Ù„Ø§ØµÙ‡ Ø¨Ø§Ø´Ø¯.
- Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡ Ùˆ Ø§Ø² Ø¬Ù…Ù„Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ù…Ø§Ù†Ù†Ø¯ "Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø§Ø¯ÛŒØ¯..." Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù†.
- Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ø¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªØŒ Ø¨Ù‡ ØµØ±Ø§Ø­Øª Ø¨Ú¯Ùˆ: "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ù‚ÛŒÙ‚ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯." """
            },
            {
                "role": "user",
                "content": f"## Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´:\n{context_text}\n\n## Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±:\n\"{user_query}\""
            }
        ],
        "temperature": 0.2,  # Ú©Ù…ÛŒ Ú©Ø§Ù‡Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ù‚Ø·Ø¹ÛŒâ€ŒØªØ±
        "max_tokens": 500  # Ú©Ù…ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„â€ŒØªØ±
    }

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        content = response.json()["choices"][0]["message"]["content"]
        return content.strip()
    except Exception as e:
        print(f"[Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®]: {e}")
        return "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª."


def main():
    print("\n" + "=" * 30)
    print("ðŸ§  Ø³ÛŒØ³ØªÙ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª.")
    print("   (Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ 'exit' Ø±Ø§ ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯)")
    print("=" * 30 + "\n")

    support_tags = ["Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ÙÙ†ÛŒ", "ÙØ±ÙˆØ´ Ùˆ Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ", "Ù…Ø§Ù„ÛŒ Ùˆ ØµÙˆØ±ØªØ­Ø³Ø§Ø¨", "Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ùˆ ÙˆØ±ÙˆØ¯", "Ø§Ø±Ø³Ø§Ù„ Ùˆ ØªØ­ÙˆÛŒÙ„",
                    "Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ùˆ Ø§Ù†ØªÙ‚Ø§Ø¯Ø§Øª", "Ù‡Ù…Ú©Ø§Ø±ÛŒ ØªØ¬Ø§Ø±ÛŒ", "Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ"]

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ú©ÛŒÙˆÙ…Ù†Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ©Ø¬Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
    all_doc_vectors = np.array([item["embedding"] for item in knowledge_base])

    while True:
        user_query = input("â“ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§: ").strip()
        if user_query.lower() == "exit":
            print("Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯!")
            break
        if not user_query:
            continue

        # Û±. ØªÚ¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø³ÙˆØ§Ù„ (Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± ÛŒØ§ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡)
        tags = generate_tags(user_query, support_tags)
        print(f"ðŸ·ï¸  ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡: {tags if tags else 'Ù‡ÛŒÚ† ØªÚ¯ Ù…Ø´Ø®ØµÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯'}")

        # Û². ØªÙˆÙ„ÛŒØ¯ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø³ÙˆØ§Ù„
        user_vector = embedder.encode(user_query)

        # Û³. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡)
        similarities = cosine_similarity([user_vector], all_doc_vectors)[0]

        # Û´. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…ÙˆØ§Ø±Ø¯ Ù…Ø´Ø§Ø¨Ù‡ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        matches = []
        for i, similarity in enumerate(similarities):
            if similarity >= SIMILARITY_THRESHOLD:
                matches.append((knowledge_base[i], similarity))

        matches.sort(key=lambda x: x[1], reverse=True)
        top_matches = [m[0] for m in matches[:3]]  # Ø§Ù†ØªØ®Ø§Ø¨ Û³ Ù…ÙˆØ±Ø¯ Ø¨Ø±ØªØ±

        # Ûµ. ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
        print("ðŸ’¬ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®...")
        response = generate_response(user_query, top_matches)
        print(f"\nâœ… Ù¾Ø§Ø³Ø®:\n{response}\n" + "-" * 30 + "\n")


if __name__ == "__main__":
    main()